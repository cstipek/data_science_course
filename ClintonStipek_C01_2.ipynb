{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "This is not a coding assignment, but for the sake of consistency we use this Jupyter notebook to work on it and submit it. For this assignment you will watch a video of a data science professional talking about a use case. Of course not every step will be easy to follow, but as data scientists we should be able to look at some complicated process in a and relate them to other common patterns we observe across use cases. So the goal of the assignment is to do this for one of the use cases listed below.\n",
    "\n",
    "You can choose any one of the following videos (you will need to be logged in as a student to access the videos):\n",
    "\n",
    "- Kaiser Permanente: [Tracking pandemics](https://learning.oreilly.com/case-studies/analytics/how-kaiser-permanente-is-using/9781491991336-video325215/)\n",
    "- Northwestern: [Sports analytics](https://learning.oreilly.com/case-studies/analytics/how-major-league-baseball-team/9781491991336-video325217/)\n",
    "- Mount Sinai: [Risk models around population health](https://learning.oreilly.com/case-studies/analytics/how-mount-sinai-operationalize/9781491991336-video325210/)\n",
    "- Thomson Reuters: [Quantitative finance](https://learning.oreilly.com/case-studies/analytics/how-thomson-reuters-is-using-a/9781491991336-video325222/)\n",
    "- Wells Fargo: [Chatbots](https://learning.oreilly.com/case-studies/analytics/how-wells-fargo-uses-ai-and-na/9781491991336-video325226/)\n",
    "- Google: [User Experience](https://learning.oreilly.com/case-studies/analytics/how-google-is-using-ai-to-enha/9781491991336-video325272/)\n",
    "- Spotify: [User Experience](https://learning.oreilly.com/case-studies/machine-learning/how-spotify-uses-machine-learn/9781491991336-video325407/)\n",
    "- Uber: [Forecasting](https://learning.oreilly.com/case-studies/machine-learning/how-uber-uses-machine-learning/9781491991336-video325398/)\n",
    "- Zocdoc: [Healthcare marketplace](https://learning.oreilly.com/case-studies/machine-learning/how-zocdoc-uses-machine-learni/9781491991336-video318567/)\n",
    "- Pythian: [Predictive maintenance](https://learning.oreilly.com/videos/strata-data-conference/9781492050520/9781492050520-video324233)\n",
    "- Astro Digital: [Food economy](https://learning.oreilly.com/videos/strata-data-conference/9781492050520/9781492050520-video324321)\n",
    "- Airbnb: [Personalization](https://learning.oreilly.com/videos/strata-data-conference/9781492050520/9781492050520-video324238)\n",
    "\n",
    "Write a short report about the use case containing the following information:\n",
    "\n",
    "1. The business problems that the use case tries to solve. <span style=\"color:red\" float:right>[5 point]</span>\n",
    "2. What parts of the data science process the were involved. <span style=\"color:red\" float:right>[5 point]</span>\n",
    "3. Challenges or questions faced during the steps of the data science process. <span style=\"color:red\" float:right>[10 point]</span>\n",
    "\n",
    "You can refer to the below diagram (also covered in class) for examples of questions that come up during the various steps of the data science process. As you watch the video, identify similar questions and their answers, and which steps of the data science process it relates to. Some use cases dive deep on one or two of these steps, and other use cases are more wholistic. Note that this is not always clear-cut so do your best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video Watched - Kaiser Permanente: Tracking pandemics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 - The business problems that the use case tries to solve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reasoning - KP wanted to cut down on flu costs, work on better community structure for vaccines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question that Kaiser Permanente was trying to track the flu via a public health integration team, a grassroots team effort. Wanted to help inform operation decisions based on flu and influenza patterns in Southern California. Trying to personalize medicine, if you have the flu can we do a virtual visit? A call? Instead of coming into the office and spreading the flu. How many tamiflus were prescribed? How many people had the flu and were not prescribed tamiflu?\n",
    "\n",
    "- What is operational value? How do you apply it to drive insight and transform how you deliver care? \n",
    "- How to divert some of the traffic of patients with the flu so they dont converge on areas where there are lots of other people - 'Tent structure' is what they called it\n",
    "- Improve the patient experience / member satisfaction - dont care who they see, just want to see someone\n",
    "- what appointments can they actually merge and change? (open-wound visit v cold symptoms)\n",
    "- Also looked at how long the flu vaccine is effective using heatmapping for vaccinations and robocalls (encouraged to come in for vaccination)\n",
    "- They explored alot of different questions and scenarios, said that some would work out and some would not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion - there were multiple questions involved and it seemed to encompass various aspects as it branched out, not entirely sure there was just one business question, but multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2 - What parts of the data science process that were involved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reasoning - unfortunately the talk did not go too far into the data, was still able to grab some insight though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working off of the CRISP-DM \n",
    "1) Business Understanding\n",
    "- Working with the questions above - how to save people from waiting and spreading the flu in a packed office\n",
    "\n",
    "2) Data understanding\n",
    "- Picked three sites\n",
    "- Looked at various factors, pop density, pollution, seasonal patterns, weather patterns, symptoms, once all of the data was understood\n",
    "\n",
    "3) Data Preparation\n",
    "- worked with trifecta - for working with data transformations\n",
    "- Lots of different datasets / inputs, had to work on making everything comparable for modeling / projections\n",
    "- worked with Python - model building and tuning\n",
    "\n",
    "4) Modeling\n",
    "- worked with Tableau - interactive dashboard for doctors and patients\n",
    "- Also mentioned modeling with Python but did not display any of the models that were made via that pathway\n",
    "\n",
    "5) Evaluation\n",
    "- Built out a two week forecast - staffing is an issue, lots of vacation planning so they need a forecast so there is enough care for all patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion - I am a bit curious to see how many years back they went? The speaker mentioned the 2016-2017 flu season but I was unsure if they were using data from the past 5 years, 10 years, xx years to evaluate the model and also what kind of accuracy it predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3 - Challenges or questions faced during the steps of the data science process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reasoning - only went through a few of the issues facing the project as a whole (funding, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and Refine Business Objective\n",
    "- Lots of different questions, but main business objective was basically how to prevent the spread of the flu\n",
    "- Questions were broad but they came up with an interesting business plan and objective of how to prevent individuals who had the flu from going into packed offices and spreading it to people who did not have it - help doctors, the public, and funding\n",
    "\n",
    "\n",
    "Acquire and Explore Data\n",
    "- Had multiple different datasets they were working with, seems they gathered all of the data and had spatial files as well as data from the CDC and other local jurisdictions\n",
    "- One of the issues I can foresee would be merging all of the data to compare, having apples and apples, not apples and oranges\n",
    "- Did not have any one person totally commited to this project, can see issues arising from people handing the data off to others and loss of translation as it goes from person to person\n",
    "- lots of different variables (age, history, etc) which I was interested in how they quantified all of the variables - which methods did they use? \n",
    "\n",
    "\n",
    "Pre-process and Enrich Data\n",
    "- mentioned the pre-process was mainly done through trifecta\n",
    "- I would also like to know more about how they designed the data to build the model, she mentioned that they used trifecta (which I have not used) and that the modeling and maintenance was done in python, but how? How many datasets did they merge? Of those datasets, how long did the cleaning process take? I know that merging spatial and data files can be relatively sticky so how did they incorporate the symptoms with the pop density? These would all take place during the design element of the engagment model - Slide 11 of Lecture 2\n",
    "\n",
    "\n",
    "Train and evaluate ML algorithms\n",
    "- modeling was done through Python, did not go into the details of the programming\n",
    "\n",
    "Summarize and communiate results\n",
    "- Tableau was used to communicate the results\n",
    "\n",
    "Deploy and monitor models in production\n",
    "- Wanted a 1 month outlook initially but at that much time its a hit or miss in terms of accuracy so they went with two weeks instead - again, relatively confused over how much data (time span) they were able to look at to build this. Would be in the Discover portion of the data science model. Slide 11 of Lecture 2\n",
    "- For the deliver aspect of the data science process the speaker mentioned running into issues with the color schemes and making sure it was a clean and easy to understand. Making sure that the final product was representative of the data and attractive to the doctors and patients\n",
    "\n",
    "\n",
    "Questions and other issues that I would see arise\n",
    "- Also want to know how they built their heatmaps, did they take socio economic patterns into play? Or were those incorporated into the pop density? Did they look at average income per household? Maybe try to target lower economic rungs first and potentially see a positive pattern from that?\n",
    "- Making an accurate predictive model for the flu seems quite challenging as I imagine that some of it is also just chance of coming into contact with someone who is also infected - How could they incorporate that into the model? There a way to include stats on probability to incorporate into the modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion - saw 48.3% more patients after they implemented this model, wait time reduced by 7.5 minutes overall during clinic hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bg w:1200](./images/data-science-process-big.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
