{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised learning\n",
    "\n",
    "In this notebook we focus on **supervised learning**, which is a set of algorithms that take **labeled** data and try to **predict** the label using the other **features** in the data. Supervised learning so far dominates applications of machine learning, although **reinforcement learning** is catching up too. Unlike **un-supervised learning** where the data is not labeled and hence there's a lot of subjectivity, **supervised learning** algorithms, once trained on data, can easily be evaluated by just comparing their **predictions** to the **labels** (in this context, we refer to the labels sometimes as **ground truth**).\n",
    "\n",
    "As usual, let's begin by reading some data. We use a bank marketing data, which has demographic and activity data about bank customers, as well as information about previous attempts to contact them for a marketing campain. The target `y` is binary and indicates whether the client signed up for a term deposit or not.\n",
    "\n",
    "You can read more about the data [here](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bank = pd.read_csv(\"../Data/bank-full.csv\", sep = \";\")\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since numeric and categorical features are often pre-processed differently, we will create variables that store the names of each to make it easier to refer to them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns are age, balance, day, duration, campaign, pdays, previous.\n",
      "Categorical columns are job, marital, education, default, housing, loan, contact, month, poutcome.\n"
     ]
    }
   ],
   "source": [
    "num_cols = bank.select_dtypes(['integer', 'float']).columns\n",
    "cat_cols = bank.select_dtypes(['object']).drop(columns = \"y\").columns\n",
    "\n",
    "print(\"Numeric columns are {}.\".format(\", \".join(num_cols)))\n",
    "print(\"Categorical columns are {}.\".format(\", \".join(cat_cols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual before we can proceed to machine learning, we need to get the data ready. And since we're doing supervised learning, we need to set aside a test data so we can later evaluate the model using that data. So let's begin by splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bank.drop(columns = \"y\"), bank[\"y\"], \n",
    "                                                    test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 38429 rows.\n",
      "Test data has 6782 rows.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data has {X_train.shape[0]} rows.\")\n",
    "print(f\"Test data has {X_test.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin our journey of trying out different algorithms in `sklearn` we do need to encode our categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehoter = OneHotEncoder(sparse = False, drop = \"first\")\n",
    "onehoter.fit(X_train[cat_cols])\n",
    "onehot_cols = onehoter.get_feature_names(cat_cols)\n",
    "X_train_onehot = pd.DataFrame(onehoter.transform(X_train[cat_cols]), columns = onehot_cols)\n",
    "X_test_onehot = pd.DataFrame(onehoter.transform(X_test[cat_cols]), columns = onehot_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some algorithms we're going to use (such as decision tree) won't require that we normalize our numeric features, but most will. Not doing so won't break the algorithm, but just as we saw in the case of k-means, it will skew the results. So let's Z-normalize our numeric features now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.135454</td>\n",
       "      <td>-0.441514</td>\n",
       "      <td>1.342893</td>\n",
       "      <td>1.905285</td>\n",
       "      <td>-0.565758</td>\n",
       "      <td>-0.410605</td>\n",
       "      <td>-0.246723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.193989</td>\n",
       "      <td>-0.393007</td>\n",
       "      <td>1.463034</td>\n",
       "      <td>0.127461</td>\n",
       "      <td>1.355238</td>\n",
       "      <td>-0.410605</td>\n",
       "      <td>-0.246723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.312355</td>\n",
       "      <td>-0.500045</td>\n",
       "      <td>1.583175</td>\n",
       "      <td>-0.685592</td>\n",
       "      <td>0.394740</td>\n",
       "      <td>-0.410605</td>\n",
       "      <td>-0.246723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.088451</td>\n",
       "      <td>-0.382982</td>\n",
       "      <td>-0.459220</td>\n",
       "      <td>-0.654471</td>\n",
       "      <td>1.035072</td>\n",
       "      <td>-0.410605</td>\n",
       "      <td>-0.246723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005696</td>\n",
       "      <td>-0.441514</td>\n",
       "      <td>-0.819643</td>\n",
       "      <td>-0.747835</td>\n",
       "      <td>0.074574</td>\n",
       "      <td>-0.410605</td>\n",
       "      <td>-0.246723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age   balance       day  duration  campaign     pdays  previous\n",
       "0  1.135454 -0.441514  1.342893  1.905285 -0.565758 -0.410605 -0.246723\n",
       "1  0.193989 -0.393007  1.463034  0.127461  1.355238 -0.410605 -0.246723\n",
       "2 -1.312355 -0.500045  1.583175 -0.685592  0.394740 -0.410605 -0.246723\n",
       "3 -0.088451 -0.382982 -0.459220 -0.654471  1.035072 -0.410605 -0.246723\n",
       "4  0.005696 -0.441514 -0.819643 -0.747835  0.074574 -0.410605 -0.246723"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "znormalizer = StandardScaler()\n",
    "znormalizer.fit(X_train[num_cols])\n",
    "X_train_norm = pd.DataFrame(znormalizer.transform(X_train[num_cols]), columns = num_cols)\n",
    "X_test_norm = pd.DataFrame(znormalizer.transform(X_test[num_cols]), columns = num_cols)\n",
    "X_train_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now join our numeric features and our one-hot-encoded categorical features into one data set that we pass to the decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurized training data has 38429 rows and 42 columns.\n",
      "Featurized test data has 6782 rows and 42 columns.\n"
     ]
    }
   ],
   "source": [
    "X_train_featurized = X_train_onehot # add one-hot-encoded columns\n",
    "X_test_featurized = X_test_onehot   # add one-hot-encoded columns\n",
    "X_train_featurized[num_cols] = X_train_norm # add numeric columns\n",
    "X_test_featurized[num_cols] = X_test_norm   # add numeric columns\n",
    "\n",
    "del X_train_norm, X_test_norm, X_train_onehot, X_test_onehot\n",
    "\n",
    "print(\"Featurized training data has {} rows and {} columns.\".format(*X_train_featurized.shape))\n",
    "print(\"Featurized test data has {} rows and {} columns.\".format(*X_test_featurized.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree classifier\n",
    "\n",
    "With our data ready, we can now train a decision tree classifier. There is a lot of detail that we leave for another time, but in this lesson we want you to see the common pattern to all or most supervised learning algorithms: \n",
    "\n",
    "1. We create an **instance** of the algorithm, along with any settings we want to use. Here we instantiate a `DecisionTreeClassifier` and specify `max_depth = 10`.\n",
    "1. We train the algorithm on the training data by calling the `fit` method.\n",
    "1. Once the model is trained, we obtain prediction by calling the `predict` method. This method is similar to the  `transform` method for the pre-processing examples we saw in prior lessons, in that you give it a data, and it uses the trained model to run predictions on the data. We want predictions for both the training and test data, so we call `predict` twice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(max_depth = 15)\n",
    "dtree.fit(X_train_featurized, y_train)\n",
    "\n",
    "y_hat_train = dtree.predict(X_train_featurized)\n",
    "y_hat_test = dtree.predict(X_test_featurized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we are only interested in evaluating the model on the test data. But when we have many models we are comparing, it's useful to evaluate each model on both the training and test data. We will see in the next lecture why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training data: 96%.\n",
      "Accuracy on the test data: 90%.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_hat_train) * 100\n",
    "acc_test = accuracy_score(y_test, y_hat_test) * 100\n",
    "\n",
    "print(\"Accuracy on the training data: {:.0f}%.\".format(acc_train))\n",
    "print(\"Accuracy on the test data: {:.0f}%.\".format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (5 minutes)\n",
    "\n",
    "We will talk in a future lecture about all different ways to evaluate classification models, but in the above snippet we are using **accuracy**, which is the percentage of predictions that match the true labels. In other words, the percentage of rows $i$ where $Y_i = \\hat Y_i$, where $Y_i$ is the $i$ target value, and $\\hat Y_i$ is the $i$th model's prediction for that value.\n",
    "\n",
    "- Return to the `DecisionTreeClassifier` above and try some larger and smaller value for `max_depth`. What do you notice about the accuracy of the training and test data as you change `max_depth`? We can use `max_depth` to \"fiddle\" with the model we get: `max_depth` is an example of what we call a **hyper-parameter** and the task of fiddling with a model's hyper-parameter is called **hyper-parameter tuning**.\n",
    "- Every algorithm has hyper-parameters. Most are unique to the algorithm: for example `max_depth` is unique to tree-based algorithms like decision trees and random forests. Return to the classifier above and look up what some other hyper-parameters are?\n",
    "\n",
    "### End of exercise\n",
    "\n",
    "So we know how accurate our model is, but what if we want to know which features contributed the most to the model? We passed a lot of features to the model, but most likely, a lot of those features were not really that useful to the prediction. Foretunately, decision trees also return **feature importance** values. Note that numeric features correspond to the numeric columns in the data. However, since we one-hot-encoded the categorical features, *every category* of every categorical column in the original data gets its own feature.\n",
    "\n",
    "Here's how we can plot the top 10 most important features to the model, starting with the most important features at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_var_imp = pd.DataFrame({\"feature\": X_train_featurized.columns, \n",
    "                           \"importance\": dtree.feature_importances_})\n",
    "df_var_imp.sort_values(by = \"importance\", ascending = False, inplace = True)\n",
    "\n",
    "import seaborn as sns\n",
    "ax = sns.barplot(x = \"importance\", y = \"feature\", data = df_var_imp.head(10), color = \"lightblue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we didn't plot it, when we use decision trees to train model a model, the trained model is (you guessed it!) a tree! This means that to get a prediction for any new data, we start at the top of the tree (called the **root**) and based on the data values we ultimately finish in one of the **leaves** of the tree, at which point we predict whatever the prediction is at the leaf we ended in.\n",
    "\n",
    "## k-nearest neighbor classifier\n",
    "\n",
    "A model trained using the k-nearest neighbor algorithm on the other hand is very different. It doesn't have a tree structure. Instead it labels a new data point by averaging the labels of the $k$ points nearest to it. For a numeric target, averaging can be done using the mean function. For categorical target, averaging means some sort of majority vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knnb = KNeighborsClassifier(n_neighbors = 25)\n",
    "knnb.fit(X_train_featurized, y_train)\n",
    "\n",
    "y_hat_train = knnb.predict(X_train_featurized)\n",
    "y_hat_test = knnb.predict(X_test_featurized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training data: 90%.\n",
      "Accuracy on the test data: 90%.\n"
     ]
    }
   ],
   "source": [
    "acc_train = accuracy_score(y_train, y_hat_train) * 100\n",
    "acc_test = accuracy_score(y_test, y_hat_test) * 100\n",
    "\n",
    "print(\"Accuracy on the training data: {:.0f}%.\".format(acc_train))\n",
    "print(\"Accuracy on the test data: {:.0f}%.\".format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (5 minutes)\n",
    "\n",
    "- The `KNeighborsClassifier` classifier has a hyper-parameter called `n_neighbors`. Try a few different values and report how it affects the accuracy on training and test data. Are you more likely to overfit if you choose a smaller value or a larger one?\n",
    "- The `KNeighborsClassifier` classifier has another hyper-parameter called `weights`. [Read up](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) on what this hyper-parameter does and change its value to something other than the default value. How does this affect your results?\n",
    "- Instead of calling the `predict` method to get predictions, in the cell below call the `predict_proba` method and examine the results. How do the results returned by the `predict` and `predict_proba` methods relate to each other? HINT: It's not enough to examine the results by just looking at them, so see if you can use `np.argmax` to give a defininitive answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.96, 0.04],\n",
       "       ...,\n",
       "       [0.76, 0.24],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnb.predict_proba(X_test_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(knnb.predict_proba(X_test_featurized), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'no', 'no', ..., 'no', 'no', 'no'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnb.predict(X_test_featurized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees also have a method called `predict_proba`. Calling `predict` returns what we call **hard predictions** and calling `predict_proba` returns **soft predictions**.\n",
    "\n",
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression classifier\n",
    "\n",
    "The decision tree and k-nn algorithms could be used for both classification and regression, with some slight modifications. The logistic regression algorithm is another popular algorithm, but it is only used for classification. Careful here: even though it has the word **regression** in it, logistic regression is a **classification** algorithm, not a **regression** algorithm. A model trained using logistic regression predicts new classes using an **equation**. This makes logistic regression very efficient. In fact, once you have your trained model, you can pull out the equation's **coefficients** and implement it even in SQL: in just one query, although if we have a lot of features it could be long query!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression(max_iter = 5000)\n",
    "logit.fit(X_train_featurized, y_train)\n",
    "\n",
    "y_hat_train = logit.predict(X_train_featurized)\n",
    "y_hat_test = logit.predict(X_test_featurized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training data: 90%.\n",
      "Accuracy on the test data: 90%.\n"
     ]
    }
   ],
   "source": [
    "acc_train = accuracy_score(y_train, y_hat_train) * 100\n",
    "acc_test = accuracy_score(y_test, y_hat_test) * 100\n",
    "\n",
    "print(\"Accuracy on the training data: {:.0f}%.\".format(acc_train))\n",
    "print(\"Accuracy on the test data: {:.0f}%.\".format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what does trained model's equation look like. To get the acutal equation we need to do some string processing with Python. Of course to get the predictions, we don't need to manually create the equation: we just need to call the `predict` method. But if we insisted on seeing the equation, we can run the next cell. \n",
    "\n",
    "**Note:** this equation gives what is called the **log-odds ratio**, and with an additional transformation that we skipped here, we can get the probability $P(Y_i = 1)$ from the log-odds ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4396585212400648 + \n",
      "job_blue-collar * -0.3016501613474136 + \n",
      "job_entrepreneur * -0.30693404015257597 + \n",
      "job_housemaid * -0.45863172176192324 + \n",
      "job_management * -0.13031246994388257 + \n",
      "job_retired * 0.21897374623294158 + \n",
      "job_self-employed * -0.2326618592801927 + \n",
      "job_services * -0.1992818518690783 + \n",
      "job_student * 0.3263207743515512 + \n",
      "job_technician * -0.19102922360988747 + \n",
      "job_unemployed * -0.18328459342437314 + \n",
      "job_unknown * -0.3491925353914526 + \n",
      "marital_married * -0.16719716956675337 + \n",
      "marital_single * 0.11386232487553828 + \n",
      "education_secondary * 0.17425345456172803 + \n",
      "education_tertiary * 0.343538576633752 + \n",
      "education_unknown * 0.19602817792456784 + \n",
      "default_yes * -0.06258227957602741 + \n",
      "housing_yes * -0.6896076803626983 + \n",
      "loan_yes * -0.4192097843688744 + \n",
      "contact_telephone * -0.1640727407736477 + \n",
      "contact_unknown * -1.6608857479040269 + \n",
      "month_aug * -0.6896864367394948 + \n",
      "month_dec * 0.585920554885654 + \n",
      "month_feb * -0.18228147352777707 + \n",
      "month_jan * -1.2267371978550146 + \n",
      "month_jul * -0.847655240794095 + \n",
      "month_jun * 0.4214386373395382 + \n",
      "month_mar * 1.5446360115617084 + \n",
      "month_may * -0.4390201850771748 + \n",
      "month_nov * -0.8809605639389108 + \n",
      "month_oct * 0.8535399876187015 + \n",
      "month_sep * 0.8465439322699875 + \n",
      "poutcome_other * 0.1861162955529122 + \n",
      "poutcome_success * 2.2333825256002537 + \n",
      "poutcome_unknown * -0.15612114439048821 + \n",
      "age * 0.018257942388496443 + \n",
      "balance * 0.03561287214696918 + \n",
      "day * 0.08828071166755738 + \n",
      "duration * 1.07307010057491 + \n",
      "campaign * -0.28864292184085655 + \n",
      "pdays * -0.02553424939128397 + \n",
      "previous * 0.020079015240534716\n"
     ]
    }
   ],
   "source": [
    "variables = list(X_train_featurized.columns)\n",
    "coefficients = map(str, list(logit.coef_[0]))\n",
    "intercept = logit.intercept_[0]\n",
    "\n",
    "var_coef_pairs = list(zip(variables, coefficients))\n",
    "equation = str(intercept) + \" + \\n\" + \" + \\n\".join([v + \" * \" + c for v,c in var_coef_pairs])\n",
    "print(equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the absolute value of the **coefficients** in the above equation can be thought of as a measure of importance of its corresponding feature, similar to the **feature importance** metric we saw with decision trees. However this is only true if the features are normalized! \n",
    "\n",
    "## Linear regression regressor\n",
    "\n",
    "So far we've only seen classification algorithms. So it's time to change course and take a look at regression algorithms. For that we need to find a numeric target. We can use the `duration` column in the data as our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train_featurized['duration']\n",
    "X_train_featurized = X_train_featurized.drop(columns = 'duration')\n",
    "\n",
    "y_test = X_test_featurized['duration']\n",
    "X_test_featurized = X_test_featurized.drop(columns = 'duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than changing the target from categorical to numeric, we don't have to do things very differently from before. The training and predicting part of the code remain very similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_featurized, y_train)\n",
    "\n",
    "y_hat_train = linreg.predict(X_train_featurized)\n",
    "y_hat_test = linreg.predict(X_test_featurized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One difference is that regression algorithms are evaluated using different metrics from classification algorithms. We used **accuracy** for the classification algorithms we saw above. We use **RMSE** for the regression algorithms we train below. We can also choose other metrics as long as they're relevant to regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the training data: 0.99093.\n",
      "RMSE on the test data: 1.00535.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse_train = mean_squared_error(y_train, y_hat_train) ** 0.5\n",
    "rmse_test = mean_squared_error(y_test, y_hat_test) ** 0.5\n",
    "\n",
    "print(\"RMSE on the training data: {:5.5f}.\".format(rmse_train))\n",
    "print(\"RMSE on the test data: {:5.5f}.\".format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (5 minutes)\n",
    "\n",
    "To get MSE (mean squared error), here's what we need to do:\n",
    "\n",
    "- find the **errors** (difference between predicted and actual value) and square them to get **squared errors**\n",
    "- add up all the squared errors to get the **sum of squared errors**\n",
    "- divide the sum of squared errors by the number of rows to get the **mean squared error**\n",
    "\n",
    "- Use the training data to calculate the MSE using `numpy` and compare it to what you get when you run `mean_squared_error`. If you use `numpy` correctly, you should not have to write any loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the training data: 0.99093.\n",
      "RMSE on the test data: 1.00535.\n"
     ]
    }
   ],
   "source": [
    "rmse_train_stratch = ((((y_train - y_hat_train) ** 2).sum())/y_train.size)**0.5\n",
    "rmse_test_stratch = ((((y_test - y_hat_test) ** 2).sum())/y_test.size)**0.5\n",
    "\n",
    "print(\"RMSE on the training data: {:5.5f}.\".format(rmse_train_stratch))\n",
    "print(\"RMSE on the test data: {:5.5f}.\".format(rmse_test_stratch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the RMSE stands for **root mean squared error**, which is the square root of the MSE.\n",
    "\n",
    "### End of exercise\n",
    "\n",
    "The next algorithm we're going to try is a neural network. Neural networks are considered complex algorithms, which means that (1) they will consume a lot of compute, (2) it's very easy to overfit with them, and (3) they are not a good option if we care about explainability. \n",
    "\n",
    "Neural networks take the data and compute their own features, and they compute an increasingly complex set of features because they are composed of layers. The features created in earlier layers affect the ones in later layers, allowing for increased complexity. In a way, you can say neural networks do their own feature engineering and are really good at it. This is one of their greatest strenth, but it also means they are very data hungry. There is no free lunch in data science and machine learning. The neural network we're going to use here will only have a few **hidden layers**, and the number of hidden neurons in each layer is a hyperparameter that can be specified. Neural networks with lots of hidden layers take us into the topic of **deep learning** and instead of `sklearn` we would need to start using libraries like `tensorflow` or `pytorch` (they are also called **frameworks**) on top of GPU machines to be able to handle the computational workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "nn = MLPRegressor(hidden_layer_sizes = [20, 10, 10, 5, 3, 2], early_stopping = False)\n",
    "nn.fit(X_train_featurized, y_train)\n",
    "\n",
    "y_hat_train = nn.predict(X_train_featurized)\n",
    "y_hat_test = nn.predict(X_test_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the training data: 0.94061.\n",
      "RMSE on the test data: 1.04254.\n"
     ]
    }
   ],
   "source": [
    "rmse_train = mean_squared_error(y_train, y_hat_train) ** 0.5\n",
    "rmse_test = mean_squared_error(y_test, y_hat_test) ** 0.5\n",
    "\n",
    "print(\"RMSE on the training data: {:5.5f}.\".format(rmse_train))\n",
    "print(\"RMSE on the test data: {:5.5f}.\".format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (5 minutes)\n",
    "\n",
    "\n",
    "- Change the number of hidden layers from 50 to 200. How does this affect runtime and RMSE?\n",
    "- Let's now train a neural network with two hidden layers instead of one. To do that, we need to provide a **list of integers** to `hidden_layer_sizes` instead of a single integer. The first integer in the list will be the number of hidden neurons in the first layer, the second integer will be  the number of hidden neurons in the second layer, and so on. **So the size of this list will be the number of hidden layers.** The more hidden layers we have the **deeper** the network. But we must be careful because adding hidden layers can increase runtime dramatically! So keep the number of hidden neurons in each layer below 20. What is the effect of adding hidden layers on overfitting?\n",
    "\n",
    "### End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks can capture very complex relationships, but they can overfit very easily. Tuning the hyper-parameters of a neural network is not an easy task. Hyper-parameters like number of hidden layers and number of hidden neurons per layer affect the neural network's **architecture**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment (Milestone 3)\n",
    "\n",
    "We saw a few examples of machine learning algorithms, so at this point it seems like once you get the data ready, machine learning is just \"plug and play\", but not so fast! \n",
    "\n",
    "In this assignment, we learn about **regularization**! Regularization is a means by which we can control how much a machine learning algorithm learns. The controlling is done using a parameter that the algorithm, called the **shrinkage parameter**, which is just an argument of the algorithm. The shrinkage parameter is an example of a **hyper-parameter**. A hyper-parameter is like a knob: by specifying a different value for the hyper-parameter, we control how the training happens, a process called **hyper-parameter tuning**. We talk about this is more detail in the next lesson.\n",
    "\n",
    "We will look at two examples of regularizaiton: LASSO and Ridge regression. Both LASSO and Ridge regression are implementations of linear regression where we try to minimize prediction error plus some penalty that depends on the model's parameters (or coefficients) and the shrinkage constant (`alpha` in the code below). LASSO penalizes the model's parameters using the sum of the **absolute values** of the parameters (this is also called **L1-regularization**), while Ridge does so based on the sum of the **squared values** of the parameters (this is also called **L2-regularization**). For reasons we cannot elaborate on here, **LASSO has the by-product that it also does feature selection**, whereas Ridge doesn't. So not all regularization results in feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_housing = pd.read_csv(\"../Data/boston-house-prices.csv\", skiprows = 1)\n",
    "df_housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the description of the data:\n",
    "\n",
    "- `CRIM`: per capita crime rate by town\n",
    "- `ZN`: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- `INDUS`: proportion of non-retail business acres per town.\n",
    "- `CHAS`: Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "- `NOX`: nitric oxides concentration (parts per 10 million)\n",
    "- `RM`: average number of rooms per dwelling\n",
    "- `AGE`: proportion of owner-occupied units built prior to 1940\n",
    "- `DIS`: weighted distances to five Boston employment centres\n",
    "- `RAD`: index of accessibility to radial highways\n",
    "- `TAX`: full-value property-tax rate per \\$10,000\n",
    "- `PTRATIO`: pupil-teacher ratio by town\n",
    "- `B`: $1000(Bk - 0.63)^2$ where $Bk$ is the proportion of black residents by town\n",
    "- `LSTAT`: % lower status of the population\n",
    "- `MEDV`: Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how regularization works, let's return to the model we trained in the lab from the data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.416942</td>\n",
       "      <td>0.344513</td>\n",
       "      <td>-1.117966</td>\n",
       "      <td>-0.270395</td>\n",
       "      <td>-0.960137</td>\n",
       "      <td>0.943640</td>\n",
       "      <td>-1.102673</td>\n",
       "      <td>0.654891</td>\n",
       "      <td>-0.523106</td>\n",
       "      <td>-1.144555</td>\n",
       "      <td>-1.601746</td>\n",
       "      <td>0.398294</td>\n",
       "      <td>-1.108176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.280002</td>\n",
       "      <td>-0.499723</td>\n",
       "      <td>-0.421068</td>\n",
       "      <td>-0.270395</td>\n",
       "      <td>-0.145806</td>\n",
       "      <td>-0.222195</td>\n",
       "      <td>0.832605</td>\n",
       "      <td>0.069475</td>\n",
       "      <td>-0.638367</td>\n",
       "      <td>-0.601866</td>\n",
       "      <td>1.175568</td>\n",
       "      <td>0.448420</td>\n",
       "      <td>0.863237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.408091</td>\n",
       "      <td>-0.499723</td>\n",
       "      <td>-0.360216</td>\n",
       "      <td>-0.270395</td>\n",
       "      <td>-0.299938</td>\n",
       "      <td>0.679704</td>\n",
       "      <td>0.108207</td>\n",
       "      <td>-0.448063</td>\n",
       "      <td>-0.523106</td>\n",
       "      <td>-0.142668</td>\n",
       "      <td>1.130038</td>\n",
       "      <td>0.434251</td>\n",
       "      <td>-0.678455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.359270</td>\n",
       "      <td>0.344513</td>\n",
       "      <td>-1.025240</td>\n",
       "      <td>-0.270395</td>\n",
       "      <td>0.171021</td>\n",
       "      <td>1.652175</td>\n",
       "      <td>-0.555824</td>\n",
       "      <td>-0.440721</td>\n",
       "      <td>-0.523106</td>\n",
       "      <td>-0.858301</td>\n",
       "      <td>-2.466811</td>\n",
       "      <td>0.377578</td>\n",
       "      <td>-1.307689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000352</td>\n",
       "      <td>-0.499723</td>\n",
       "      <td>1.021988</td>\n",
       "      <td>-0.270395</td>\n",
       "      <td>0.239524</td>\n",
       "      <td>0.017747</td>\n",
       "      <td>-0.580681</td>\n",
       "      <td>0.076309</td>\n",
       "      <td>1.666847</td>\n",
       "      <td>1.539070</td>\n",
       "      <td>0.811330</td>\n",
       "      <td>0.359545</td>\n",
       "      <td>-0.272453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.416942  0.344513 -1.117966 -0.270395 -0.960137  0.943640 -1.102673   \n",
       "1 -0.280002 -0.499723 -0.421068 -0.270395 -0.145806 -0.222195  0.832605   \n",
       "2 -0.408091 -0.499723 -0.360216 -0.270395 -0.299938  0.679704  0.108207   \n",
       "3 -0.359270  0.344513 -1.025240 -0.270395  0.171021  1.652175 -0.555824   \n",
       "4 -0.000352 -0.499723  1.021988 -0.270395  0.239524  0.017747 -0.580681   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0  0.654891 -0.523106 -1.144555 -1.601746  0.398294 -1.108176  \n",
       "1  0.069475 -0.638367 -0.601866  1.175568  0.448420  0.863237  \n",
       "2 -0.448063 -0.523106 -0.142668  1.130038  0.434251 -0.678455  \n",
       "3 -0.440721 -0.523106 -0.858301 -2.466811  0.377578 -1.307689  \n",
       "4  0.076309  1.666847  1.539070  0.811330  0.359545 -0.272453  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_housing.drop(columns = 'MEDV')\n",
    "y = df_housing['MEDV']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a linear regression algorithm to predict `MEDV` from the remaining features. <span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning - Need to import the linear regression model to train based on the X and y provided above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg=LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "y_linreg_train = linreg.predict(X_train)\n",
    "y_linreg_test = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - Was able to train the X and y based on the medv by using the linear regression fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate the model and report the performance on both training and test data. These numbers will serve as our benchmark performance. <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to change the \n",
    "\n",
    "print(\"Accuracy on the training data: {:.0f}%.\".format(acc_train))\n",
    "print(\"Accuracy on the test data: {:.0f}%.\".format(acc_test))\n",
    "\n",
    "Reasoning - Will import the mean_squared_error package from sklearn to get the idea of the performance and then square that to get it into the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training data: 4.768.\n",
      "Accuracy on the test data: 3.872.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "rmse_train = mean_squared_error(y_train, y_linreg_train) **0.5\n",
    "rmse_test = mean_squared_error(y_test, y_linreg_test) **0.5\n",
    "\n",
    "print(\"Accuracy on the training data: {:5.3f}.\".format(rmse_train))\n",
    "print(\"Accuracy on the test data: {:5.3f}.\".format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - Able to get the accuracy, both were relatively close with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train a regularized version of `LinearRegression` called `Lasso` (you can load it from the same library). `Lasso` has an argument called `alpha`, which is the **shrinkage parameter** we referred to earlier.\n",
    "\n",
    "3. Let `alpha = 0.000001` and train a `Lasso` algorithm. Show that the resulting model is practically identical to the one we trained with `LinearRegression`. There are different ways to show this, so you will need to think of a way. <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning - will need to import the Lasso algorithm and then train the same data on this method, will copy the rmse for the data but run it over the lassoo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training data: 4.768.\n",
      "Accuracy on the test data: 3.872.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_reg = Lasso(alpha=0.000001)\n",
    "\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "y_lasso_train = lasso_reg.predict(X_train)\n",
    "\n",
    "y_lasso_test = lasso_reg.predict(X_test)\n",
    "\n",
    "\n",
    "rmse_train_lasso = mean_squared_error(y_train, y_lasso_train) **0.5\n",
    "rmse_test_lasso = mean_squared_error(y_test, y_lasso_test) **0.5\n",
    "\n",
    "print(\"Accuracy on the training data: {:5.3f}.\".format(rmse_train_lasso))\n",
    "print(\"Accuracy on the test data: {:5.3f}.\".format(rmse_test_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - should they be the same? A little confused on this, or are we learning how similar methods can be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Iteratively train a new `Lasso` model, letting `alpha` change each time to one of the values given by `alpha_vals` below, keeping track of the performance on the training and test data each time, and storing the model's coefficients each time (the `coef_` attribute of the trained model). <span style=\"color:red\" float:right>[5 point]</span>\n",
    "\n",
    "To make it easier, we have laid out general layout of the code. You can use this if you want or write your own program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning - Will follow the directions pretty closely, I will first train the lasso model with an alpha of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg_4 = Lasso(alpha=0.000001)\n",
    "\n",
    "lasso_reg_4.fit(X_train, y_train)\n",
    "\n",
    "y_lasso_train = lasso_reg_4.predict(X_train)\n",
    "\n",
    "y_lasso_test = lasso_reg_4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_vals = np.arange(0.01, 5, .01) # values of alpha we want to iterate over\n",
    "# this data stores the alpha we tried, and the coefficients (coef) we got for each feature (col)\n",
    "iter_coefs = pd.DataFrame(columns = ['alpha', 'col', 'coef'])\n",
    "iter_train_perf = [] # use this to store training data performance for each iteration\n",
    "iter_test_perf = [] # use this to store test data performance for each iteration\n",
    "\n",
    "\n",
    "\n",
    "for i in alpha_vals:\n",
    "    lasso_reg_4 = Lasso(alpha=i)\n",
    "    lasso_reg_4.fit(X_train, y_train)\n",
    "    y_lasso_train = lasso_reg_4.predict(X_train)\n",
    "    y_lasso_test = lasso_reg_4.predict(X_test)\n",
    "    rmse_train = mean_squared_error(y_train, y_lasso_train) **0.5\n",
    "    rmse_test = mean_squared_error(y_test, y_lasso_test) **0.5\n",
    "    iter_train_perf.append(rmse_train)\n",
    "    iter_test_perf.append(rmse_test)\n",
    "    for j in range(len(X_train.columns)):\n",
    "        iter_coefs = iter_coefs.append({'alpha': i, 'col':(X_train.columns[j]), 'coef':lasso_reg_4.coef_[j]},ignore_index=True)\n",
    "\n",
    "# loop over the alpha values and do this:\n",
    "    # fit a model with alpha\n",
    "    # evaluate the model on training and test data\n",
    "    # append training performance to iter_train_perf\n",
    "    # append test performance to iter_test_perf\n",
    "    # create a DataFrame storing alpha (repeated), feature name matching coefficient\n",
    "    # append the above DataFrame to iter_coefs\n",
    "    \n",
    "    ###ignoreindex=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - it worked so I will count it as a win, just followed the directions and then added it to the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Using a visual, show how the performance on the training and test data changed as we gradually increased `alpha`. <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning - will first take a look at the data and organize it and then use plt to make a basic visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iter_perf = pd.DataFrame(iter_train_perf, columns = ['train_rmse'])\n",
    "\n",
    "iter_perf['test_rmse']=iter_test_perf\n",
    "iter_perf['alpha']=((iter_perf.index+1)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train_rmse  test_rmse  alpha\n",
      "0    4.769179   3.864341   0.01\n",
      "1    4.771164   3.858193   0.02\n",
      "2    4.773882   3.853969   0.03\n",
      "3    4.777247   3.854448   0.04\n",
      "4    4.781567   3.856379   0.05\n",
      "(499, 3)\n"
     ]
    }
   ],
   "source": [
    "print(iter_perf.head())\n",
    "print(iter_perf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axis = plt.subplots()\n",
    "\n",
    "axis.plot(iter_perf.alpha, iter_perf.train_rmse, marker=\"*\", label='Training Data')\n",
    "\n",
    "axis.plot(iter_perf.alpha, iter_perf.test_rmse, marker=\".\", label='Testing Data')\n",
    "\n",
    "axis.set_xlabel('ALPHA')\n",
    "axis.set_ylabel('RMSE')\n",
    "\n",
    "axis.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - Found that the training and testing data were relatively similar in terms of their slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Using a visual, show how the model's coefficients changed as we gradually increased the shrinkage parameter `alpha`. HINT: They should appear to be shrinking toward zero as you increase `alpha`! <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning - same concept as above but will not need to do any data organization on this one, will just plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axis = plt.subplots()\n",
    "axis.plot(iter_coefs.alpha, iter_coefs.coef, marker=\".\", label='Alpha Data')\n",
    "\n",
    "axis.set_xlabel('Alpha')\n",
    "axis.set_ylabel('Coef')\n",
    "axis.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - Able to fnd a sloping alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Show that `Ridge` and `Lasso` return the same trained model when `alpha = 0.00001` (i.e. close to zero). <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning - WIll just switch from Lasso to Ridge on this one from earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridgereg = Ridge(alpha=0.00001)\n",
    "ridgereg.fit(X_train, y_train)\n",
    "y_train_ridge = ridgereg.predict(X_train)\n",
    "y_test_ridge = ridgereg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_ridge_train = mean_squared_error(y_train, y_train_ridge)**0.5\n",
    "rmse_ridge_test = mean_squared_error(y_test, y_test_ridge)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training data: 4.768.\n",
      "Accuracy on the test data: 3.872.\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on the training data: {:5.3f}.\".format(rmse_ridge_train))\n",
    "print(\"Accuracy on the test data: {:5.3f}.\".format(rmse_ridge_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - Again, same values for training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Repeat step 4 this time using `Ridge` instead of `Lasso`. We will use the following range for `alpha`: <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning - same concept as 4, will just drag the code down from above and make slight modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_vals_ridge = np.arange(0.01, 5, .01) # values of alpha we want to iterate over\n",
    "iter_coefs_ridge = pd.DataFrame(columns = ['alpha', 'col', 'coef'])\n",
    "iter_train_perf_ridge = [] # use this to store training data performance for each iteration\n",
    "iter_test_perf_ridge = [] # use this to store test data performance for each iteration\n",
    "\n",
    "\n",
    "\n",
    "for i in alpha_vals_ridge:\n",
    "    ridge_reg = Ridge(alpha=i)\n",
    "    ridge_reg.fit(X_train, y_train)\n",
    "    y_ridge_train = ridge_reg.predict(X_train)\n",
    "    y_ridge_test = ridge_reg.predict(X_test)\n",
    "    rmse_train_ridge = mean_squared_error(y_train, y_ridge_train) **0.5\n",
    "    rmse_test_ridge = mean_squared_error(y_test, y_ridge_test) **0.5\n",
    "    iter_train_perf_ridge.append(rmse_train_ridge)\n",
    "    iter_test_perf_ridge.append(rmse_test_ridge)\n",
    "    for j in range(len(X_train.columns)):\n",
    "        iter_coefs_ridge = iter_coefs_ridge.append({'alpha': i, 'col':(X_train.columns[j]), 'coef':ridge_reg.coef_[j]},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - It worked so again, I hope that it was correctly coded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Using a visual, show how the performance on the training and test data changed as we gradually increased `alpha`. <span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning - will drag the code down from above again after organizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iter_perf_ridge = pd.DataFrame(iter_train_perf_ridge, columns = ['train_rmse'])\n",
    "\n",
    "iter_perf_ridge['test_rmse']=iter_test_perf_ridge\n",
    "iter_perf_ridge['alpha']=((iter_perf_ridge.index+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAbj0lEQVR4nO3de5RU5bnn8e9DN02jXBoQBW0iaCLKrdumhZMFThQZDHhJjLiEBDSGLMYkEpwsozjBYzRZZ/BoJgRIBlkclByMxDNIwnHUHD3GozmMQCMgNxFUxA5oNxi5Cd00/cwfVWDRVFdfqF0F9f4+a9XqXXu/e+/n7VZ+tS/1bnN3REQkXG2yXYCIiGSXgkBEJHAKAhGRwCkIREQCpyAQEQmcgkBEJHD5Ue/AzPKACuCv7n59g2WdgUXAF+K1PObuT6Ta3jnnnOO9e/eOqFoRkdy0evXq3e7ePdmyyIMAmApsBjolWfYDYJO732Bm3YEtZvaUu9c2trHevXtTUVERUakiIrnJzD5obFmkp4bMrBi4DpjfSBMHOpqZAR2AT4C6KGsSEZETRX1EMBO4F+jYyPI5wDJgZ7zNre5eH3FNIiKSILIjAjO7Hqhy99Upml0LrAXOB0qBOWZ20ikkM5tsZhVmVlFdXR1NwSIigYry1NAw4EYz2w4sBkaY2aIGbe4AnvWYbcD7wKUNN+Tu89y93N3Lu3dPeq1DRERaKbIgcPf73b3Y3XsD44BX3H1Cg2Y7gGsAzOw8oC/wXlQ1iYjIyTJx19AJzOxOAHefC/wMeNLM1gMG3OfuuzNdk4hkTtW+w9zx5Cre232A8zsX8tdPD2EY5xedOL1z7+GUy6Nqm639NtV2597DXNy9Awu+fQXndixM69/EzrRhqMvLy701t49W7TvM5H9ezaEjdXyw5+Bp/0dXW7XN1bYFeW3Ye0g3B7bWhKFf4Oc3DWzxema22t3Lky4LJQimL13PohU7IqhIRCTz2uW3YcvPRze7faogyPipoUzrO/0Faup0R6qI5I6r+nbnH8cOStv2cn6sodfvvZpR/c/LdhkiImlTXNQ+rdcJcv6I4NxOhXTv0C7bZYiInBIjdjoIg+oDNWndds4HAcDuAzX06tKeqv01Ok0kkmV5Bnl5xnkdC+l3ficen5j0tLVkUBBBoP/QREQal/PXCEREJDUFgYhI4BQEIiKBUxCIiAROQSAiEjgFgYhI4BQEIiKBUxCIiAROQSAiEjgFgYhI4BQEIiKBUxCIiAROQSAiEjgFgYhI4BQEIiKBUxCIiAROQSAiEjgFgYhI4BQEIiKBUxCIiAROQSAiEjgFgYhI4BQEIiKBUxCIiAROQSAiEjgFgYhI4BQEIiKBUxCIiAQu8iAwszwzW2NmzzWy/CozW2tmG83sP6KuR0RETpSfgX1MBTYDnRouMLMi4DfAV919h5mdm4F6REQkQaRHBGZWDFwHzG+kyTeBZ919B4C7V0VZj4iInCzqU0MzgXuB+kaWXwJ0MbNXzWy1md0WcT0iItJAZEFgZtcDVe6+OkWzfGAwsaOGa4EHzOySJNuabGYVZlZRXV0dTcEiIoGK8ohgGHCjmW0HFgMjzGxRgzaVwIvuftDddwOvASUNN+Tu89y93N3Lu3fvHmHJIiLhiSwI3P1+dy92997AOOAVd5/QoNkfgSvNLN/MzgKGEruwLCIiGZKJu4ZOYGZ3Arj7XHffbGYvAm8Ru44w3903ZLomEZGQmbtnu4YWKS8v94qKimyXISJyRjGz1e5enmyZvlksIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAiDwIzyzOzNWb2XIo2V5jZUTMbG3U9IiJyokwcEUwFNje20MzygEeAP2WgFhERaSDSIDCzYuA6YH6KZlOAJUBVlLWIiEhyUR8RzATuBeqTLTSzC4CbgLkR1yEiIo2ILAjM7Hqgyt1Xp2g2E7jP3Y82sa3JZlZhZhXV1dVprVNEJHTm7tFs2Ox/AhOBOqAQ6AQ86+4TEtq8D1j87TnAZ8Bkd/9DY9stLy/3ioqKSGoWEclVZrba3cuTLcuPaqfufj9wf7yAq4B7EkMg3qZPQpFPAs+lCgEREUm/yIKgMWZ2J4C767qAyBnqyJEjVFZWcvjw4WyXIg0UFhZSXFxM27Ztm71ORoLA3V8FXo1PJw0Ad/92JmoRkVNXWVlJx44d6d27N2bW9AqSEe7Onj17qKyspE+fPk2vEKdvFotIix0+fJhu3bopBE4zZka3bt1afKSmIBCRVlEInJ5a83dJGQRmNiJhuk+DZd9o8d5ERNJgz549lJaWUlpaSo8ePbjggguOv6+trW3WNu644w62bNmSss2vf/1rnnrqqXSUzPDhw+nbty+DBg3i0ksv5Yc//CF79+5NuU59fT0zZsxIy/5TcvdGX8CbyaaTvc/Ua/DgwS4i2bVp06YWr/Px3kN+y9zl/vG+Q2mt5cEHH/RHH330pPn19fV+9OjRtO7rVAwbNszXrFnj7u41NTU+depUHzFiRMp1jhw54p07d27xvpL9fYAKb+Tf1aZODVkj08nei4g0ata/b2XV9k+Y9fLWyPaxbds2BgwYwJ133klZWRm7du1i8uTJlJeX079/fx5++OHjbYcPH87atWupq6ujqKiIadOmUVJSwpe//GWqqmIj3kyfPp2ZM2cebz9t2jSGDBlC3759Wb58OQAHDx7k5ptvpqSkhPHjx1NeXs7atWtT1llQUMBjjz3G1q1b2bhxIwA33HADgwcPpn///syfHxuVZ9q0aezfv5/S0lJuu+22RtudqqbuGvJGppO9F5EAPfSvG9m0c1+jy1du/4TE760uWrGDRSt2YAZDendNuk6/8zvx4A39W1XPpk2beOKJJ5g7N3aD4owZM+jatSt1dXVcffXVjB07ln79+p2wzt69e/nKV77CjBkz+NGPfsSCBQuYNm3aSdt2d1auXMmyZct4+OGHefHFF5k9ezY9evRgyZIlrFu3jrKysmbVmZ+fz6BBg3j77bfp378/CxcupGvXrnz22WeUl5dz8803M2PGDObPn39CsCRr16VLl1b9ro5p6ojgIjNbZmb/mjB97H3z700SkWCVFhfR7ewC2sTPIbQx6HZ2AaXFRZHs7+KLL+aKK644/v7pp5+mrKyMsrIyNm/ezKZNm05ap3379owePRqAwYMHs3379qTb/sY3vnFSm7/85S+MGzcOgJKSEvr3b36AeUJC/vKXvzx+RFJZWcm7776bdJ3mtmuJpo4IvpYw/ViDZQ3fi0iAmvPJ/SdL1/O7lTtol9+G2qP1jB7Qg5/fNDCSes4+++zj01u3buVXv/oVK1eupKioiAkTJiS9tbKgoOD4dF5eHnV1dUm33a5du5PaJP5j3hJ1dXVs2LCByy67jJdffpnXXnuNN954g/bt2zN8+PCkdTa3XUulPCJw9/9IfAHLgX3A5vh7EZEm7T5Qw7eGXsjS7w/jW0MvpPpATUb2u2/fPjp27EinTp3YtWsXf/pT+h97Mnz4cJ555hkA1q9fn/SIo6Ha2lruu+8+vvjFL9KvXz/27t1L165dad++PRs3bmTVqlVA7PQRcDx0Gmt3qlIeEZjZXGC2u280s87A/wOOAl3N7B53fzotVYhITnt84udjnf386wMytt+ysjL69evHgAEDuOiiixg2bFja9zFlyhRuu+02Bg0aRFlZGQMGDKBz585J29566620a9eOmpoaRo0axbPPPgvAddddx7x58ygpKeHSSy9l6NChx9eZNGkSgwYNory8nHnz5jXa7lSkHH3UzDa6e//49N3AVe7+dTPrAbzg7penpYoW0OijItm3efNmLrvssmyXcVqoq6ujrq6OwsJCtm7dyqhRo9i6devxT/PZkOzvcyqjjyZ+M+O/Av8C4O4f6VuFIiJw4MABrrnmGurq6nB3Hn/88ayGQGs0Ve2n8QfM/BUYBkwCMLN8oH3EtYmInPaKiopYvTrV87dOf00FwX8DZgE9gLvd/aP4/GuA/xtlYSIikhkpg8Dd3wG+mmT+n4D0X34XEZGMa+quoVmplrv7D9NbjoiIZFpTp4buBDYAzwA70fhCIiI5p6khJnoC84BriT2Ivi2wzN0XuvvCqIsTEUkmHcNQAyxYsICPPvro+PvmDE3dHHV1deTl5VFaWkr//v0pLS1l5syZ1NfXp1zvvffeY/Hixae8/5Zq6hrBHmAuMNfMLgDGAxvN7D53/+dMFCgi0lC3bt2OD8T205/+lA4dOnDPPfe0eDsLFiygrKyMHj16APDEE0+krcaOHTser/Hjjz9m3Lhx7N+/nwceeKDRdY4FwbGxizKlWU8oM7My4G5gAvACcGbfKyUimffhSnj9F7GfEVq4cCFDhgyhtLSU73//+9TX11NXV8fEiRMZOHAgAwYMYNasWfz+979n7dq13HrrrcePJJozNPXWrVsZOnQoQ4YM4YEHHqCoqOnB88477zwef/xxZs+eDcC7777LlVdeyeWXX87gwYNZsWIFEBt2+s9//jOlpaXMmjWr0Xbp1tTF4oeA64HNwGLgfndPPhqTiITphWnw0frUbWr2wccbwOvB2sB5A6Bdp8bb9xgIo1v+ZK4NGzawdOlSli9fTn5+PpMnT2bx4sVcfPHF7N69m/XrY3V++umnFBUVMXv2bObMmUNpaelJ22psaOopU6Zwzz33cMsttzBnzpxm13bJJZdw6NAh9uzZQ8+ePXnppZcoLCzk7bff5vbbb2fFihXMmDGDOXPm8Ic//AGAzz77LGm7dGvqYvEDwHtASfz1D/FvFBvg7j4o7RWJSO45vDcWAhD7eXhv6iBopZdffplVq1ZRXh4bSeHQoUP06tWLa6+9li1btjB16lTGjBnDqFGjmtxWw6GpX3/9dQBWrFjB888/D8A3v/lNpk+f3uz6jg3pU1NTw1133cW6devIz89vdCjp5rY7VU0FgZ45ICKpNeeT+4crYeGNcLQW8grg5vnQa0jaS3F3vvOd7/Czn/3spGVvvfUWL7zwArNmzWLJkiXMmzcv5baaOzR1c73zzjucddZZdOvWjenTp9OrVy8WLVrEkSNH6NChQ9J1fvGLXzSr3alqahjqD5K9gEpgeCQViUju6TUEbl8GI34S+xlBCACMHDmSZ555ht27dwOxu4t27NhBdXU17s4tt9zCQw89xJtvvgnELuju37+/RfsYMmQIS5cuBWj2HT5VVVV873vfY8qUKUDstFPPnj0xMxYuXHj8SKFhPY21S7emrhF0An4AXAAsA14C7gLuAdYCT0VSlYjknl5DIguAYwYOHMiDDz7IyJEjqa+vp23btsydO5e8vDwmTZqEu2NmPPLII0DsdtHvfve7tG/fnpUrm3cRe9asWUycOJFHHnmEMWPGNDrk9LFnDdfW1lJQUMDtt9/O1KlTAbjrrrsYO3YsTz/9NCNHjjz+wJvLL7+co0ePUlJSwqRJkxptl25NDUP9R+BvxJ5DcA3QBSgAprp76qczR0TDUItkX8jDUB88eJCzzjoLM2PRokUsXbqUJUuWZLusE6R7GOqL3H1gfCPzgd3AF9y9ZcdSIiI5YtWqVdx9993U19fTpUuXtH73IFuaCoIjxybc/aiZva8QEJGQXXXVVce/KJYrmgqCEjPbF582oH38/bHbR9N//5eIiGRUU0NM5GWqEBE5sxy78Cqnl9bcWdSsISZERBIVFhayZ8+eyG5nlNZxd/bs2UNhYWGL1juzHqwpIqeF4uJiKisrqa6uznYp0kBhYSHFxcUtWkdBICIt1rZtW/r00cADuUKnhkREAqcgEBEJXORBYGZ5ZrbGzJ5LsuxbZvZW/LXczEqirkdERE6UiWsEU4k9zyDZdw7eB77i7n8zs9HEHos5NAM1iYhIXKRHBGZWDFwHzE+23N2Xu/vf4m/fAFp2qVtERE5Z1KeGZgL3Aqmf2BwzidhjME9iZpPNrMLMKnS7mohIekUWBGZ2PVDl7k0+39jMriYWBPclW+7u89y93N3Lu3fvnuZKRUTCFuU1gmHAjWY2BigEOpnZInefkNjIzAYRO3U02t33RFiPiIgkEdkRgbvf7+7F7t4bGAe8kiQEvgA8C0x093eiqkVERBqX8W8Wm9mdAO4+F/h7oBvwm/jgVXWNPThBRESikfIJZacjPaFMRKTlUj2hTN8sFhEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwkQeBmeWZ2Rozey7JMjOzWWa2zczeMrOyqOsREZETZeKIYCqwuZFlo4EvxV+Tgf+dgXpERCRBpEFgZsXAdcD8Rpp8Dfitx7wBFJlZzyhrEhGRE0V9RDATuBeob2T5BcCHCe8r4/NERCRDIgsCM7seqHL31amaJZnnSbY12cwqzKyiuro6bTWKiEi0RwTDgBvNbDuwGBhhZosatKkEeiW8LwZ2NtyQu89z93J3L+/evXtU9YqIBCmyIHD3+9292N17A+OAV9x9QoNmy4Db4ncP/R2w1913RVWTiIicLD/TOzSzOwHcfS7wPDAG2AZ8BtyR6XpEREKXkSBw91eBV+PTcxPmO/CDTNQgIiLJ6ZvFIiKBUxCIiAROQSAiEjgFgYhI4BQEIiKBUxCIiAROQSAiEjgFgYhI4BQEIiKBUxCIiAROQSAiEjgFgYhI4BQEIiKBUxCIiAROQSAiEjgFgYhI4BQEIiKBUxCIiAROQSAiEjgFgYhI4DLy8PrTwocrYd3voPod+PRDMIPCTlBXC/kFcGjv5/Mam25u2x4DYdhU6DUk270WEWlSGEHw4Up4YgzUH8nM/j79AN5+DjqeD34UMCg4G2oPxpa36wi1B2Lz23WC+lpo0w5q9n0eKjX7Y23bF7UujE7Xtp2LoXtfKBmvoBQ5TYQRBNtfh/q6zO93/87k8w98lLrNvoTpvR+mtaSs+/QD+OA/oWJBPCjrY/MLOoLXQZu28ZAkFpI1+zgemLXx6cLOsVDPK4DD+06fkIu6bcFZMPR7UP7tLP3xJFeFEQS9r4S8tnC0NtuVSKITQvCj1Mv3//Xz6X2VkZV02ntuKvzbdGh7FrQ7G+qPQpv8JEeb8emaY0eeHWMfhtq0hdr40WZh58+Dtn3nMycQFbRpZ+6e7RpapLy83CsqKlq+YqauEdQegEOfpL/jIpIZhV2gfRc4cpCTTusWdIQjCUF7tC72IbNmP8ePXGv2gQHtOn9+urdd59gp4Px2rf+3pq4WzvlSq68/mtlqdy9PuiyYIMikiidhzW9jRyCn4yefbLU9WnviaTERabk2beGO51scBqmCIIxTQ5lW/u0gDy+b5cOV8J8zYfe25J94TqfgOp3a7q+Cgx9n+68np4P6I7Hrnmm82UJBIJnVawiM+122qzgzHQvRXetP/+A609qeSUHbpm3sumcaKQhEzhQK0WilOlo9HcLqFK8RpKIgEBGBoINWQ0yIiAROQSAiEjgFgYhI4BQEIiKBUxCIiAROQSAiErgzbogJM6sGPmjl6ucAu9NYzplAfQ6D+hyGU+nzhe7ePdmCMy4IToWZVTQ21kauUp/DoD6HIao+69SQiEjgFAQiIoELLQjmZbuALFCfw6A+hyGSPgd1jUBERE4W2hGBiIg0EEQQmNlXzWyLmW0zs2nZriddzGyBmVWZ2YaEeV3N7CUz2xr/2SVh2f3x38EWM7s2O1WfGjPrZWZ/NrPNZrbRzKbG5+dsv82s0MxWmtm6eJ8fis/P2T4fY2Z5ZrbGzJ6Lvw+hz9vNbL2ZrTWzivi8aPvt7jn9AvKAd4GLgAJgHdAv23WlqW//BSgDNiTM+0dgWnx6GvBIfLpfvO/tgD7x30letvvQij73BMri0x2Bd+J9y9l+E3sCbof4dFtgBfB3udznhL7/CPgd8Fz8fQh93g6c02BepP0O4YhgCLDN3d9z91pgMfC1LNeUFu7+GvBJg9lfAxbGpxcCX0+Yv9jda9z9fWAbsd/NGcXdd7n7m/Hp/cBm4AJyuN8eE39iOm3jLyeH+wxgZsXAdcD8hNk53ecUIu13CEFwAfBhwvvK+LxcdZ6774LYP5rAufH5Ofd7MLPewOXEPiHndL/jp0jWAlXAS+6e830GZgL3AvUJ83K9zxAL+X8zs9VmNjk+L9J+h/CEMksyL8RbpXLq92BmHYAlwN3uvs8sWfdiTZPMO+P67e5HgVIzKwKWmtmAFM3P+D6b2fVAlbuvNrOrmrNKknlnVJ8TDHP3nWZ2LvCSmb2dom1a+h3CEUEl0CvhfTGwM0u1ZMLHZtYTIP6zKj4/Z34PZtaWWAg85e7PxmfnfL8B3P1T4FXgq+R2n4cBN5rZdmKnc0eY2SJyu88AuPvO+M8qYCmxUz2R9juEIFgFfMnM+phZATAOWJblmqK0DLg9Pn078MeE+ePMrJ2Z9QG+BKzMQn2nxGIf/f8J2Ozu/ythUc7228y6x48EMLP2wEjgbXK4z+5+v7sXu3tvYv/PvuLuE8jhPgOY2dlm1vHYNDAK2EDU/c72FfIMXYUfQ+zukneBn2S7njT262lgF3CE2CeDSUA34N+BrfGfXRPa/yT+O9gCjM52/a3s83Bih75vAWvjrzG53G9gELAm3ucNwN/H5+dsnxv0/yo+v2sop/tM7O7GdfHXxmP/XkXdb32zWEQkcCGcGhIRkRQUBCIigVMQiIgETkEgIhI4BYGISOAUBCINmNlNZuZmdmn8fe/EEV4T2j1pZu/HR4l808y+nDB/bIO2Bxq8/+9mdtjMOkfZF5HmUBCInGw88BdiX2Rqyo/dvZTYiJCPt3Afq4CbWl6eSHopCEQSxMcwGkbsy3nNCYJjXgO+2Mx9XAx0AKYTCwSRrFIQiJzo68CL7v4O8ImZlTVzvRuA9QnvH42fMlobHzU00Xhi3wp/HegbH1xMJGsUBCInGk9skDPiP5v6xP5o/B/6ycSOIo75sbuXHns1WGccsTHk64FngVvSULdIq4UwDLVIs5hZN2AEMMDMnNjT7Rz4TYrVfuzu/6cF+xhEbGCwl+JDZxcA7wG/bm3dIqdKRwQinxsL/NbdL3T33u7eC3if2NC+6TIe+Gl8+73d/XzgAjO7MI37EGkRBYHI58YTG/890RLgfxA7l1+Z8Grt6ZxxSfaxlJZdmBZJK40+KiISOB0RiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigfv/tZvaV6rTKQcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axis = plt.subplots()\n",
    "\n",
    "axis.plot(iter_perf_ridge.alpha, iter_perf_ridge.train_rmse, marker=\"*\", label='Training Data')\n",
    "\n",
    "axis.plot(iter_perf_ridge.alpha, iter_perf_ridge.test_rmse, marker=\".\", label='Testing Data')\n",
    "\n",
    "axis.set_xlabel('ALPHA')\n",
    "axis.set_ylabel('RMSE')\n",
    "\n",
    "axis.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - Quite interested by my results to be honest, something doesnt seem right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Using a visual, show how the model's coefficients changed as we gradually increased the shrinkage parameter `alpha`.  <span style=\"color:red\" float:right>[1 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning - will run a similar plot to earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axis = plt.subplots()\n",
    "axis.plot(iter_coefs_ridge.alpha, iter_coefs_ridge.coef, marker=\".\", label='Alpha Data')\n",
    "\n",
    "axis.set_xlabel('Alpha')\n",
    "axis.set_ylabel('Coef')\n",
    "axis.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - Again, a little confused by these results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Based on the results, briefly describe the effect of changing `alpha` on the coefficients of both `Ridge` and `Lasso`. What value of `alpha` would you choose for each case? You do not need to give a precise answer, but choose a number. <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alpha choice seems to be an important aspect of the data management, \n",
    "\n",
    "\n",
    "#https://www.analyticsvidhya.com/blog/2016/01/ridge-lasso-regression-python-complete-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
