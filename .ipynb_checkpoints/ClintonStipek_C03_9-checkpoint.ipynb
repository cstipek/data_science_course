{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "In this assignment, we see how using convolutional neural networks improves our model's accuracy. Recall the fashion MNIST data set from the previous assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "data = keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below cell to train a neural network that more or less imitates what a logistic regression classifier would do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 - 2s - loss: 15.1547 - sparse_categorical_accuracy: 0.8101 - 2s/epoch - 844us/step\n",
      "313/313 - 1s - loss: 20.2560 - sparse_categorical_accuracy: 0.7869 - 603ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20.255992889404297, 0.786899983882904]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_baseline = Sequential()\n",
    "model_baseline.add(Flatten(input_shape = (28, 28)))\n",
    "model_baseline.add(Dense(10, activation = 'sigmoid'))\n",
    "\n",
    "model_baseline.compile(\n",
    "    optimizer = keras.optimizers.RMSprop(learning_rate = 1e-3),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model_baseline.fit(x_train, y_train, epochs = 50, verbose = 0)\n",
    "\n",
    "model_baseline.evaluate(x_train, y_train, verbose = 2)\n",
    "model_baseline.evaluate(x_test, y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 884us/step - loss: 20.2560 - sparse_categorical_accuracy: 0.7869\n",
      "\n",
      "Test score: 20.255992889404297\n",
      "\n",
      "Test Accuracy: 0.786899983882904\n"
     ]
    }
   ],
   "source": [
    "score_baseline = model_baseline.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"\\nTest score:\", score_baseline[0])\n",
    "print(\"\\nTest Accuracy:\", score_baseline[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the previous assignment, the above network seems to do a good job at classifying shirts, but not other clothing items. Let's see if we can improve the classfier by using convolutional layers.\n",
    "\n",
    "- Copy the code in the above cell below, then modify the network so the first two layers are a convolution layer with 32 filters followed by a 5x5 max-pooling layer. Also add a dense layer with 32 neurons prior to the output layer. Train the new network for 50 epochs and report the accuracy. <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scratch and Sources\n",
    "\n",
    "- https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-fashion-mnist-clothing-classification/\n",
    "- https://stackoverflow.com/questions/47665391/keras-valueerror-input-0-is-incompatible-with-layer-conv2d-1-expected-ndim-4\n",
    "- Deep Learning with TF 2 and Keras - chapter 4, 5, 8\n",
    "\n",
    "PLEASE NOTE - TOP PART IS ASSIGNMENT Q - BOTTOM PART IT DEVIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "label_dimensions = 10\n",
    "\n",
    "training_size = len(x_train)\n",
    "test_size = len(x_test)\n",
    "\n",
    "print(x_train.max())\n",
    "x_train = np.asarray(x_train, dtype=np.float32) / 255\n",
    "x_test = np.asarray(x_test, dtype=np.float32) / 255\n",
    "\n",
    "x_train = x_train.reshape((training_size, 28, 28, 1))\n",
    "x_test = x_test.reshape((test_size, 28, 28, 1))\n",
    "print(x_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28,28,1)\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "#Conv layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "#pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(5,5)))\n",
    "#Flatten\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "#Adding dense layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#Output layer\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 5, 5, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                25632     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,282\n",
      "Trainable params: 26,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.RMSprop(learning_rate = 1e-3),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.5533 - sparse_categorical_accuracy: 0.8041\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.3806 - sparse_categorical_accuracy: 0.8650\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3416 - sparse_categorical_accuracy: 0.8792\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3173 - sparse_categorical_accuracy: 0.8866\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2993 - sparse_categorical_accuracy: 0.8927\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2861 - sparse_categorical_accuracy: 0.8971\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2751 - sparse_categorical_accuracy: 0.9015\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2672 - sparse_categorical_accuracy: 0.9042\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2600 - sparse_categorical_accuracy: 0.9060\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2538 - sparse_categorical_accuracy: 0.9091\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2472 - sparse_categorical_accuracy: 0.9108\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2426 - sparse_categorical_accuracy: 0.9123\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2381 - sparse_categorical_accuracy: 0.9132\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2334 - sparse_categorical_accuracy: 0.9161\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2300 - sparse_categorical_accuracy: 0.9168\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2279 - sparse_categorical_accuracy: 0.9186\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2240 - sparse_categorical_accuracy: 0.9180\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2208 - sparse_categorical_accuracy: 0.9201\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2177 - sparse_categorical_accuracy: 0.9214\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2151 - sparse_categorical_accuracy: 0.9220\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2133 - sparse_categorical_accuracy: 0.9229\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2104 - sparse_categorical_accuracy: 0.9238\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2088 - sparse_categorical_accuracy: 0.9238\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2065 - sparse_categorical_accuracy: 0.9251\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2046 - sparse_categorical_accuracy: 0.9257\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2034 - sparse_categorical_accuracy: 0.9262\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2024 - sparse_categorical_accuracy: 0.9272\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1991 - sparse_categorical_accuracy: 0.9283\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1985 - sparse_categorical_accuracy: 0.9289\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1971 - sparse_categorical_accuracy: 0.9290\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1956 - sparse_categorical_accuracy: 0.9293\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1941 - sparse_categorical_accuracy: 0.9299\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1926 - sparse_categorical_accuracy: 0.9294\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1923 - sparse_categorical_accuracy: 0.9300\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1900 - sparse_categorical_accuracy: 0.9317\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1887 - sparse_categorical_accuracy: 0.9326\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1889 - sparse_categorical_accuracy: 0.9318\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1870 - sparse_categorical_accuracy: 0.9326\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1870 - sparse_categorical_accuracy: 0.9328\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1869 - sparse_categorical_accuracy: 0.9324\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1843 - sparse_categorical_accuracy: 0.9336\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1844 - sparse_categorical_accuracy: 0.9339\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1825 - sparse_categorical_accuracy: 0.9343\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1821 - sparse_categorical_accuracy: 0.9351\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1810 - sparse_categorical_accuracy: 0.9345\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1808 - sparse_categorical_accuracy: 0.9350\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1800 - sparse_categorical_accuracy: 0.9352\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1795 - sparse_categorical_accuracy: 0.9358\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1790 - sparse_categorical_accuracy: 0.9357\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1762 - sparse_categorical_accuracy: 0.9363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20fcd26e610>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 - 3s - loss: 0.1735 - sparse_categorical_accuracy: 0.9373 - 3s/epoch - 2ms/step\n",
      "313/313 - 1s - loss: 0.3422 - sparse_categorical_accuracy: 0.8981 - 1s/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34222647547721863, 0.8981000185012817]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train, y_train, verbose = 2)\n",
    "model.evaluate(x_test, y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add another four layers to the network: a convolution layer with 64 filters and a 3x3 max-pooling layer, followed by another convolution layer with 128 filters and a 3x3 max-pooling layer. Train the new network for 100 epochs and report the accuracy. <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can also call 'input_shape' into the input_shape call for Conv2D layers\n",
    "model_new = Sequential()\n",
    "\n",
    "#conv layer 1\n",
    "model_new.add(Conv2D(32,kernel_size=3,\n",
    "                     padding='same',#Make sure 'padding' is same or the 3rd layer will not work with input shape\n",
    "                    activation='relu',\n",
    "                    input_shape=(28, 28, 1)))\n",
    "model_new.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "#conv layer 2\n",
    "model_new.add(Conv2D(64, kernel_size=3,\n",
    "                     padding = 'same',\n",
    "                    activation='relu',\n",
    "                    input_shape=(28,28,1)))\n",
    "model_new.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "#conv layer 3\n",
    "model_new.add(Conv2D(128,kernel_size=3,\n",
    "                     padding='same',\n",
    "                    activation='relu',\n",
    "                    input_shape=(28, 28, 1)))\n",
    "model_new.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "#flatten\n",
    "model_new.add(Flatten(input_shape=(28,28)))\n",
    "\n",
    "#Dense layers\n",
    "model_new.add(Dense(32, activation='relu'))\n",
    "model_new.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.compile(\n",
    "    optimizer = keras.optimizers.RMSprop(learning_rate = 1e-3),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 9, 9, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 9, 9, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 3, 3, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 1, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 97,130\n",
      "Trainable params: 97,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20fe1488c70>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.fit(x_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 - 5s - loss: 0.3687 - sparse_categorical_accuracy: 0.8701 - 5s/epoch - 3ms/step\n",
      "313/313 - 1s - loss: 0.4579 - sparse_categorical_accuracy: 0.8477 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45793744921684265, 0.8476999998092651]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.evaluate(x_train, y_train, verbose=2)\n",
    "model_new.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many parameters did we add to the model by adding the layers in the previous step? <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 5, 5, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                25632     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,282\n",
      "Trainable params: 26,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 9, 9, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 9, 9, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 3, 3, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 1, 1, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 97,130\n",
      "Trainable params: 97,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Went from 26282 to 97130 parameters by adding the additional layers in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional CNN Work - Please note it will take a while to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model for 1rst part of assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = len(x_train) #Setting the length of the training size for reshaping\n",
    "test_size = len(x_test) #Setting the length of the test size for reshaping\n",
    "label_dimensions = 10 #Number of classes for output - to pass into y_test / train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(x_train.max())\n",
    "x_train = np.asarray(x_train, dtype=np.float32) / 255\n",
    "x_test = np.asarray(x_test, dtype=np.float32) / 255\n",
    "\n",
    "x_train = x_train.reshape((training_size, 28, 28, 1))\n",
    "x_test = x_test.reshape((test_size, 28, 28, 1))\n",
    "print(x_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, label_dimensions) #Please note that I am adding in label dimensions - will increase parameters\n",
    "y_test = tf.keras.utils.to_categorical(y_test, label_dimensions)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 11, 11, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 3872)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                123936    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,586\n",
      "Trainable params: 124,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Building a CNN model for first question\n",
    "inputs = tf.keras.Input(shape=(28,28,1))\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(inputs)#First conv layer\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(5,5), strides=2)(x)#First maxpooling layer\n",
    "x = tf.keras.layers.Flatten()(x)#Flatten\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x) #Adding in dense 32 layer\n",
    "predictions = tf.keras.layers.Dense(label_dimensions, activation='softmax')(x) #Output layer - please note label dimensions\n",
    "model_update = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "model_update.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model now\n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "model_update.compile(loss='categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a strategy\n",
    "strategy = None\n",
    "config = tf.estimator.RunConfig(train_distribute=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\7w9\\AppData\\Local\\Temp\\1\\tmp_ttj89rp\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\7w9\\\\AppData\\\\Local\\\\Temp\\\\1\\\\tmp_ttj89rp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\7w9\\Anaconda3\\lib\\site-packages\\keras\\backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "#Convert model into a convenient estimator\n",
    "estimator = tf.keras.estimator.model_to_estimator(model_update, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define input functions for training and for testing\n",
    "def input_fn(images, labels, epochs, batch_size):\n",
    "    #convert the inputs to a dataset\n",
    "    dataset=tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    #Shuffle, repeat, and batch\n",
    "    SHUFFLE_SIZE=5000\n",
    "    dataset=dataset.shuffle(SHUFFLE_SIZE).repeat(epochs).batch(batch_size)\n",
    "    dataset=dataset.prefetch(None)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\7w9\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\7w9\\\\AppData\\\\Local\\\\Temp\\\\1\\\\tmp_ttj89rp\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: C:\\Users\\7w9\\AppData\\Local\\Temp\\1\\tmp_ttj89rp\\keras\\keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 6 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\7w9\\AppData\\Local\\Temp\\1\\tmp_ttj89rp\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 2.3590937, step = 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-21a3603a0b21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m estimator_train_result = estimator.train(input_fn = lambda:input_fn(x_train,\n\u001b[0m\u001b[0;32m      6\u001b[0m                                         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                         batch_size=BATCH_SIZE))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1184\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1215\u001b[0m                                            self.config)\n\u001b[0;32m   1216\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0m\u001b[0;32m   1218\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m                                              saving_listeners)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1531\u001b[0m         \u001b[1;31m# trace should be enabled for every step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurrent_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1533\u001b[1;33m           \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1534\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mcurrent_step\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m         tf.compat.v1.logging.warn('Training with estimator made no steps. '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    780\u001b[0m       \u001b[0mSame\u001b[0m \u001b[1;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m     \"\"\"\n\u001b[1;32m--> 782\u001b[1;33m     return self._sess.run(\n\u001b[0m\u001b[0;32m    783\u001b[0m         \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1309\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1311\u001b[1;33m         return self._sess.run(\n\u001b[0m\u001b[0;32m   1312\u001b[0m             \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1399\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1401\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1402\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1403\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     \u001b[1;31m# Do session run.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1468\u001b[0m     \u001b[0mrun_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRunMetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1469\u001b[1;33m     outputs = _WrappedSession.run(\n\u001b[0m\u001b[0;32m   1470\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m         \u001b[0mfetches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactual_fetches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1232\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1192\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1371\u001b[0m                            run_metadata)\n\u001b[0;32m   1372\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1375\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1360\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1361\u001b[0m                                       target_list, run_metadata)\n\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1451\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1452\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1453\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1454\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1455\u001b[0m                                             run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###PLEASE NOTE THIS CELL WILL TAKE AT LEAST 10-15 MINUTES###\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS=50\n",
    "estimator_train_result = estimator.train(input_fn = lambda:input_fn(x_train,\n",
    "                                        y_train, epochs=EPOCHS,\n",
    "                                        batch_size=BATCH_SIZE))\n",
    "\n",
    "print(estimator_train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_train_result.evaluate(x_train, y_train, verbose = 2)\n",
    "estimator_train_result.evaluate(x_test, y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model for 2nd part of assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a CNN model\n",
    "inputs = tf.keras.Input(shape=(28,28,1))\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(5,5), strides=2)(x)\n",
    "x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=2)(x)\n",
    "x = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=2)(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(LABEL_DIMENSIONS, activation='softmax')(x)\n",
    "model_update_2 = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "model_update_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_update_2.compile(loss='categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert model into a convenient estimator\n",
    "estimator_2 = tf.keras.estimator.model_to_estimator(model_update_2, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###PLEASE NOTE THIS CELL WILL TAKE AT LEAST 10-15 MINUTES###\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS=100\n",
    "estimator_train_result_2 = estimator_2.train(input_fn = lambda:input_fn(x_train,\n",
    "                                        y_train, epochs=EPOCHS,\n",
    "                                        batch_size=BATCH_SIZE))\n",
    "\n",
    "print(estimator_train_result_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
